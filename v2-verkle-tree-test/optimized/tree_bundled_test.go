// optimized/tree_bundled_test.go

package optimized

import (
	"fmt"
	"strings"
	"testing"
	"time"
	"encoding/json"
)

// TestBundledMultiProof10 - bundled proof –¥–ª—è 10 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
func TestBundledMultiProof10(t *testing.T) {
	testBundledMultiProof(t, 10)
}

// TestBundledMultiProof50 - bundled proof –¥–ª—è 50 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
func TestBundledMultiProof50(t *testing.T) {
	testBundledMultiProof(t, 50)
}

// TestBundledMultiProof100 - bundled proof –¥–ª—è 100 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
func TestBundledMultiProof100(t *testing.T) {
	testBundledMultiProof(t, 100)
}

// testBundledMultiProof - –æ–±—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è bundled proof
func testBundledMultiProof(t *testing.T, numUsers int) {
	t.Log("\n" + strings.Repeat("=", 100))
	t.Logf("üß™ BUNDLED MULTI-PROOF TEST: %d –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", numUsers)
	t.Log(strings.Repeat("=", 100))
	
	// 1. –°–æ–∑–¥–∞–µ–º –¥–µ—Ä–µ–≤–æ –∏ –∑–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–º–∏
	t.Log("\nüìù –®–ê–ì 1: –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ –∏ –≤—Å—Ç–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
	
	srs := getTestSRS(t)
	config := NewConfig(srs)
	tree, err := New(config, nil)
	if err != nil {
		t.Fatalf("Failed to create tree: %v", err)
	}
	defer tree.Close()
	
	// –í—Å—Ç–∞–≤–ª—è–µ–º –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏
	totalUsers := numUsers * 10 // 10x –±–æ–ª—å—à–µ —á–µ–º –Ω—É–∂–Ω–æ –¥–ª—è proof
	userIDs := make([]string, totalUsers)
	
	batch := tree.NewBatch()
	for i := 0; i < totalUsers; i++ {
		userID := fmt.Sprintf("bundled_test_%d_user_%05d", numUsers, i)
		userIDs[i] = userID
		
		userData := &UserData{
			Balances: map[string]float64{
				"USD": float64(i * 100),
				"BTC": float64(i) * 0.01,
				"ETH": float64(i) * 0.1,
			},
			Metadata: map[string]interface{}{
				"level": i % 100,
				"verified": true,
			},
			Timestamp: time.Now().Unix(),
		}
		
		data, _ := json.Marshal(userData)
		batch.Add(userID, data)
	}
	
	tree.CommitBatch(batch)
	tree.WaitForCommit()
	
	t.Logf("   ‚úì –í—Å—Ç–∞–≤–ª–µ–Ω–æ %d –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –¥–µ—Ä–µ–≤–æ", totalUsers)
	
	// –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è proof
	proofUserIDs := userIDs[:numUsers]
	
	// 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è BUNDLED Multi-Proof
	t.Logf("\nüìù –®–ê–ì 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è BUNDLED Multi-Proof (%d –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)", numUsers)
	
	startBundled := time.Now()
	bundledProof, err := tree.GenerateMultiProof(proofUserIDs)
	bundledDuration := time.Since(startBundled)
	
	if err != nil {
		t.Fatalf("Failed to generate bundled proof: %v", err)
	}
	
	t.Logf("   ‚úì Bundled proof —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
	t.Logf("   –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: %v", bundledDuration)
	t.Logf("   Is bundled: %v", bundledProof.IsBundled)
	
	// –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä bundled proof
	bundledSize := calculateProofSize(bundledProof)
	
	t.Logf("\n   üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ Bundled Proof:")
	t.Logf("      - User IDs: %d", len(bundledProof.UserIDs))
	t.Logf("      - Path commitments: %d", len(bundledProof.Path))
	t.Logf("      - Path indices: %d", len(bundledProof.PathIndices))
	t.Logf("      - Children hashes levels: %d", len(bundledProof.ChildrenHashes))
	t.Logf("      - Total size: %d bytes (~%.2f KB)", bundledSize, float64(bundledSize)/1024)
	
	// 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è N –æ—Ç–¥–µ–ª—å–Ω—ã—Ö Single Proofs –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
	t.Logf("\nüìù –®–ê–ì 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è %d –æ—Ç–¥–µ–ª—å–Ω—ã—Ö Single Proofs (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)", numUsers)
	
	startSingle := time.Now()
	singleProofs := make([]*Proof, numUsers)
	
	for i, userID := range proofUserIDs {
		proof, err := tree.GenerateProof(userID)
		if err != nil {
			t.Fatalf("Failed to generate single proof %d: %v", i, err)
		}
		singleProofs[i] = proof
	}
	
	singleDuration := time.Since(startSingle)
	
	// –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä single proofs
	totalSingleSize := 0
	for _, proof := range singleProofs {
		totalSingleSize += calculateProofSize(proof)
	}
	
	t.Logf("   ‚úì %d single proofs —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã", numUsers)
	t.Logf("   –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: %v", singleDuration)
	t.Logf("   Total size: %d bytes (~%.2f KB)", totalSingleSize, float64(totalSingleSize)/1024)
	
	// 4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤
	t.Log("\nüìù –®–ê–ì 4: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Bundled vs Single Proofs")
	
	sizeReduction := float64(totalSingleSize-bundledSize) / float64(totalSingleSize) * 100
	compressionRatio := float64(totalSingleSize) / float64(bundledSize)
	
	t.Log("\n   " + strings.Repeat("-", 80))
	t.Logf("   | %-30s | %15s | %15s |", "Metric", "Bundled", "Single (sum)")
	t.Log("   " + strings.Repeat("-", 80))
	t.Logf("   | %-30s | %12d KB | %12d KB |", "Size", bundledSize/1024, totalSingleSize/1024)
	t.Logf("   | %-30s | %15v | %15v |", "Generation Time", bundledDuration, singleDuration)
	t.Logf("   | %-30s | %12.2f ms | %12.2f ms |", "Time per user", 
		float64(bundledDuration.Microseconds())/float64(numUsers)/1000,
		float64(singleDuration.Microseconds())/float64(numUsers)/1000)
	t.Log("   " + strings.Repeat("-", 80))
	
	t.Logf("\n   üéØ –≠–∫–æ–Ω–æ–º–∏—è —Ä–∞–∑–º–µ—Ä–∞: %.2f%% (%.2fx compression)", sizeReduction, compressionRatio)
	
	if sizeReduction > 0 {
		t.Logf("   ‚úÖ Bundled proof –Ω–∞ %d bytes –º–µ–Ω—å—à–µ!", totalSingleSize-bundledSize)
	} else {
		t.Logf("   ‚ö†Ô∏è  Single proofs –º–µ–Ω—å—à–µ (–Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ!)")
	}
	
	// –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
	if bundledDuration < singleDuration {
		speedup := float64(singleDuration) / float64(bundledDuration)
		t.Logf("   ‚úÖ Bundled proof –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ –≤ %.2fx —Ä–∞–∑!", speedup)
	} else {
		t.Logf("   ‚ö†Ô∏è  Single proofs –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ")
	}
	
	// 5. –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è Bundled Proof
	t.Log("\nüìù –®–ê–ì 5: –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è Bundled Multi-Proof")
	
	startVerify := time.Now()
	valid, err := VerifyBundledProof(bundledProof, config)
	verifyDuration := time.Since(startVerify)
	
	if err != nil {
		t.Fatalf("Bundled proof verification error: %v", err)
	}
	
	if !valid {
		t.Fatal("Bundled proof is INVALID!")
	}
	
	t.Logf("   ‚úÖ Bundled proof VALID")
	t.Logf("   –í—Ä–µ–º—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏: %v", verifyDuration)
	t.Logf("   –ù–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: %.2f ms", float64(verifyDuration.Microseconds())/float64(numUsers)/1000)
	
	// 6. –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—Å–µ—Ö Single Proofs –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
	t.Logf("\nüìù –®–ê–ì 6: –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è %d Single Proofs (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)", numUsers)
	
	startVerifySingle := time.Now()
	
	for i, proof := range singleProofs {
		valid, err := VerifySingleProof(proof, config)
		if err != nil {
			t.Fatalf("Single proof %d verification error: %v", i, err)
		}
		if !valid {
			t.Fatalf("Single proof %d is INVALID!", i)
		}
	}
	
	verifySingleDuration := time.Since(startVerifySingle)
	
	t.Logf("   ‚úÖ –í—Å–µ %d single proofs –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã", numUsers)
	t.Logf("   –í—Ä–µ–º—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏: %v", verifySingleDuration)
	t.Logf("   –ù–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: %.2f ms", float64(verifySingleDuration.Microseconds())/float64(numUsers)/1000)
	
	// 7. –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
	t.Log("\n" + strings.Repeat("=", 100))
	t.Log("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
	t.Log(strings.Repeat("=", 100))
	
	t.Logf("\nüîπ –†–∞–∑–º–µ—Ä:")
	t.Logf("   Bundled:      %d bytes (%.2f KB)", bundledSize, float64(bundledSize)/1024)
	t.Logf("   Single (sum): %d bytes (%.2f KB)", totalSingleSize, float64(totalSingleSize)/1024)
	t.Logf("   üíæ –≠–∫–æ–Ω–æ–º–∏—è:  %.2f%% (ratio %.2fx)", sizeReduction, compressionRatio)
	
	t.Logf("\nüîπ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è:")
	t.Logf("   Bundled: %v", bundledDuration)
	t.Logf("   Single:  %v", singleDuration)
	if bundledDuration < singleDuration {
		t.Logf("   ‚ö° –£—Å–∫–æ—Ä–µ–Ω–∏–µ: %.2fx", float64(singleDuration)/float64(bundledDuration))
	}
	
	t.Logf("\nüîπ –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è:")
	t.Logf("   Bundled: %v", verifyDuration)
	t.Logf("   Single:  %v", verifySingleDuration)
	if verifyDuration < verifySingleDuration {
		t.Logf("   ‚ö° –£—Å–∫–æ—Ä–µ–Ω–∏–µ: %.2fx", float64(verifySingleDuration)/float64(verifyDuration))
	}
	
	t.Log("\n" + strings.Repeat("=", 100))
	t.Logf("‚úÖ BUNDLED MULTI-PROOF TEST (%d –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π) –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!", numUsers)
	t.Log(strings.Repeat("=", 100))
}

// TestBundledComparison - —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ bundled proof
func TestBundledComparison(t *testing.T) {
	t.Log("\n" + strings.Repeat("=", 100))
	t.Log("üß™ –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –¢–ï–°–¢: Bundled Multi-Proof —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤")
	t.Log(strings.Repeat("=", 100))
	
	sizes := []int{5, 10, 25, 50, 100}
	
	srs := getTestSRS(t)
	config := NewConfig(srs)
	
	// –°–æ–∑–¥–∞–µ–º –¥–µ—Ä–µ–≤–æ —Å –¥–∞–Ω–Ω—ã–º–∏
	tree, _ := New(config, nil)
	defer tree.Close()
	
	totalUsers := 1000
	userIDs := make([]string, totalUsers)
	
	batch := tree.NewBatch()
	for i := 0; i < totalUsers; i++ {
		userID := fmt.Sprintf("comparison_user_%05d", i)
		userIDs[i] = userID
		
		userData := &UserData{
			Balances: map[string]float64{"USD": float64(i * 100)},
		}
		data, _ := json.Marshal(userData)
		batch.Add(userID, data)
	}
	
	tree.CommitBatch(batch)
	tree.WaitForCommit()
	
	t.Logf("\n‚úì –î–µ—Ä–µ–≤–æ —Å–æ–∑–¥–∞–Ω–æ: %d –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n", totalUsers)
	
	// –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
	type result struct {
		size           int
		bundledSize    int
		singleSize     int
		bundledTime    time.Duration
		singleTime     time.Duration
		compressionRatio float64
		speedup        float64
	}
	
	results := make([]result, 0, len(sizes))
	
	for _, size := range sizes {
		t.Logf("üìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: %d –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π...", size)
		
		proofUsers := userIDs[:size]
		
		// Bundled proof
		startB := time.Now()
		bundledProof, _ := tree.GenerateMultiProof(proofUsers)
		bundledTime := time.Since(startB)
		bundledSize := calculateProofSize(bundledProof)
		
		// Single proofs
		startS := time.Now()
		totalSingleSize := 0
		for _, userID := range proofUsers {
			proof, _ := tree.GenerateProof(userID)
			totalSingleSize += calculateProofSize(proof)
		}
		singleTime := time.Since(startS)
		
		compressionRatio := float64(totalSingleSize) / float64(bundledSize)
		speedup := float64(singleTime) / float64(bundledTime)
		
		results = append(results, result{
			size:             size,
			bundledSize:      bundledSize,
			singleSize:       totalSingleSize,
			bundledTime:      bundledTime,
			singleTime:       singleTime,
			compressionRatio: compressionRatio,
			speedup:          speedup,
		})
	}
	
	// –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
	t.Log("\n" + strings.Repeat("=", 120))
	t.Log("üìä –°–í–û–î–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê:")
	t.Log(strings.Repeat("=", 120))
	
	t.Log("\n| Users | Bundled Size | Single Size | Compression | Bundled Time | Single Time | Speedup |")
	t.Log("|-------|--------------|-------------|-------------|--------------|-------------|---------|")
	
	for _, r := range results {
		t.Logf("| %5d | %9d KB | %8d KB | %9.2fx | %12v | %11v | %6.2fx |",
			r.size,
			r.bundledSize/1024,
			r.singleSize/1024,
			r.compressionRatio,
			r.bundledTime,
			r.singleTime,
			r.speedup,
		)
	}
	
	t.Log("\n" + strings.Repeat("=", 120))
	
	// –í—ã–≤–æ–¥—ã
	t.Log("\nüìà –í–´–í–û–î–´:")
	
	avgCompression := 0.0
	avgSpeedup := 0.0
	for _, r := range results {
		avgCompression += r.compressionRatio
		avgSpeedup += r.speedup
	}
	avgCompression /= float64(len(results))
	avgSpeedup /= float64(len(results))
	
	t.Logf("   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è: %.2fx", avgCompression)
	t.Logf("   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: %.2fx", avgSpeedup)
	t.Logf("   ‚Ä¢ Bundled Multi-Proof —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è %d+ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", sizes[0])
	
	t.Log("\n" + strings.Repeat("=", 120))
	t.Log("‚úÖ –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù!")
	t.Log(strings.Repeat("=", 120))
}

// calculateProofSize - –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä proof –≤ –±–∞–π—Ç–∞—Ö
func calculateProofSize(proof *Proof) int {
	size := 0
	
	// UserIDs (strings)
	for _, id := range proof.UserIDs {
		size += len(id)
	}
	
	// UserIDHashes (32 bytes each)
	size += len(proof.UserIDHashes) * 32
	
	// Path (commitments)
	for _, p := range proof.Path {
		size += len(p)
	}
	
	// PathIndices (int = 8 bytes)
	size += len(proof.PathIndices) * 8
	
	// ChildrenHashes
	for _, level := range proof.ChildrenHashes {
		for _, hash := range level {
			size += len(hash)
		}
	}
	
	// KZG data
	size += len(proof.KZGOpeningProof)
	size += len(proof.KZGCommitment)
	size += len(proof.RootHash)
	
	// IsBundled (1 byte)
	size += 1
	
	return size
}
